# -*- coding: utf-8 -*-
"""Book_Recommender.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nqdzQVmPO5BrGBtnGP91FS2_SMk4MGiw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

books = pd.read_csv('Books.csv', on_bad_lines='skip', encoding='latin-1')
books.head(2)

books.rename(columns={
    "Book-Title": "title",
    "Book-Author": "author",
    "Year-Of-Publication": "year",
    "Publisher": "publisher",
    "Image-URL-S": "img_url",
},inplace=True)

books.head(

)

users = pd.read_csv('Users.csv', on_bad_lines='skip', encoding='latin-1')

users.head()

ratings = pd.read_csv('Ratings.csv', on_bad_lines='skip', encoding='latin-1')

ratings.head()

ratings.rename(columns={
    "User-ID": "user_id",
    "Book-Rating": "rating",
},inplace=True)

ratings.head()

ratings_with_books=ratings.merge(books, on='ISBN')

ratings_with_books.head()

num_rating=ratings_with_books.groupby('title')['rating'].count().reset_index()

num_rating.head()

num_rating.rename(columns={
    "rating": "num_of_rating"
},inplace=True)

num_rating.head()

final_rating=ratings_with_books.merge(num_rating, on='title')

final_rating.head(2)

final_rating.drop_duplicates(['user_id','title'], inplace=True)

reduced_data = final_rating.sample(frac=0.01, random_state=42)

# Create the pivot table with the smaller sample
book_pivot = reduced_data.pivot_table(columns='user_id', index='title', values="rating")

# Convert to sparse matrix (optional, but recommended for memory efficiency)
from scipy.sparse import csr_matrix
book_pivot_sparse = csr_matrix(book_pivot.fillna(0))

book_pivot_sparse

book_pivot.head()

from sklearn.neighbors import NearestNeighbors
model = NearestNeighbors(algorithm='brute')

model.fit(book_pivot_sparse)

#distances, suggestions = model.kneighbors(book_pivot.iloc[237, :].values.reshape(1, -1))

# Check if all values are NaN
all_nan = book_pivot.isnull().all().all()

if all_nan:
    print("All values in the DataFrame are NaN.")
else:
    print("Not all values in the DataFrame are NaN.")
    print("Number of NaN values:", book_pivot.isnull().sum().sum())

import pandas as pd
from sklearn.impute import SimpleImputer

# Assuming 'book_pivot' is your original DataFrame
imputer = SimpleImputer(strategy='mean')
book_pivot_imputed = imputer.fit_transform(book_pivot)

# Convert the imputed array back to a Pandas DataFrame
book_pivot_imputed_df = pd.DataFrame(book_pivot_imputed, index=book_pivot.index, columns=book_pivot.columns)

# Now you can use .iloc on the DataFrame
# Example: book_pivot_imputed_df.iloc[:5, :5]

distances, suggestions = model.kneighbors(book_pivot_imputed_df.iloc[237, :].values.reshape(1, -1))

distances

suggestions

book_pivot_imputed_df.index[5]

for i in range(len(suggestions)):
    print(book_pivot_imputed_df.index[suggestions[i]])

books_name=book_pivot_imputed_df.index

import pickle
pickle.dump(model,open('model.pkl','wb'))
pickle.dump(books_name,open('/books_name.pkl','wb'))
pickle.dump(final_rating,open('final_rating.pkl','wb'))
pickle.dump(book_pivot,open('book_pivot.pkl','wb'))

def recommend_book(book_name):
    book_id = np.where(book_pivot_imputed_df.index == book_name)[0][0]
    distances, suggestions = model.kneighbors(book_pivot_imputed_df.iloc[book_id, :].values.reshape(1, -1))

    for i in range(len(suggestions)):
     print(book_pivot.index[suggestions[i]])
     for j in book_pivot.index[suggestions[i]]:
        print(j)

book_name = 'Animal Farm'
recommend_book(book_name)